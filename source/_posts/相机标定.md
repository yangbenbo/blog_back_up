---
title: 相机标定
date: 2020-12-26 14:54:40
categories:
- ROS
tags:
- 标定
---

# 相机内参标定

# 手眼标定
这篇文章的图片已经解释的很清楚了[机器人手眼标定Ax=xB（eye to hand和eye in hand）及平面九点法标定](https://blog.csdn.net/yaked/article/details/77161160?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control)
1. eye-in-hand
    两次运动,机器人底座和标定板的位恣关系不变,求解相机和机器人末端的位姿关系
    ![eye-in-hand](eye-in-hand.png)    
2. eye-on-base
    两次运动,机器人末端和标定板的位恣关系不变,求解相机和机器人基座之间的位恣关系
    ![eye-on-base](eye-on-base.png)

## franka realsense 标定
主要使用了三个包:
- [aruco_ros](https://github.com/pal-robotics/aruco_ros), 相机获取二维码位恣,二维码可通过[ArUco markers generator!](https://chev.me/arucogen/)生成,记得一定要选择*Original ArUco*
ID和size根据需要选择,这两个参数在之后的launch文件中使用,这里选用的是ID:582,size:50
- [easy_handeye](https://github.com/IFL-CAMP/easy_handeye), 结合moveit标定的包
- [realsense-ros](https://github.com/IntelRealSense/realsense-ros), realsense ros驱动

则有标定launch文件如下,标定后得到camera_link到panda_link0的位恣变换,然后在launch文件中使用tf2_ros中的static_transform_publisher发布出来即可使用
    
        <?xml version="1.0" ?>
        <launch>
        
            <!--  franka -->
            <arg name="robot_ip" default="192.168.10.102"/>
            <arg name="move_group" default="panda_arm" />
            <arg name="robot_base_frame" default="panda_link0"/>
            <arg name="robot_effector_frame" default="panda_EE"/>
        
            <!--  marker  -->
            <arg name="markerId"        default="582"/>
            <arg name="markerSize"      default="0.05"/>    <!-- in m -->
            <arg name="marker_frame"    default="aruco_marker_frame"/>
            <arg name="ref_frame"       default="camera_link"/>  <!-- leave empty and the pose will be published wrt param parent_name -->
            <arg name="camera_frame"    default="camera_color_optical_frame"/>
            <arg name="corner_refinement" default="LINES" /> <!-- NONE, HARRIS, LINES, SUBPIX -->
        
            <!--  launch franka  -->
            <include file="$(find franka_control)/launch/franka_control.launch">
                <arg name="robot_ip" value="$(arg robot_ip)" />
                <arg name="load_gripper" value="true" />
            </include>
            <include file="$(find panda_moveit_config)/launch/panda_moveit.launch">
                <arg name="load_gripper" value="true" />
            </include>
        
            <!--  panda_link0 to world TF  -->
            <node pkg="tf2_ros" type="static_transform_publisher" name="virtual_joint_broadcaster_1" args="0 0 0 0 0 0 world panda_link0" />
        
            <!--  realsense  -->
            <include file="$(find realsense2_camera)/launch/rs_camera.launch"/>
        
            <!--  marker  -->
            <node pkg="aruco_ros" type="single" name="aruco_single">
                <remap from="/camera_info" to="/camera/color/camera_info" />
                <remap from="/image" to="/camera/color/image_raw" />
                <param name="image_is_rectified" value="True"/>
                <param name="marker_size"        value="$(arg markerSize)"/>
                <param name="marker_id"          value="$(arg markerId)"/>
                <param name="reference_frame"    value="$(arg ref_frame)"/>   <!-- frame in which the marker pose will be refered -->
                <param name="camera_frame"       value="$(arg camera_frame)"/>
                <param name="marker_frame"       value="$(arg marker_frame)" />
                <param name="corner_refinement"  value="$(arg corner_refinement)" />
            </node>
            <node pkg="image_view" type="image_view" name="iamge_view" args="image:=/aruco_single/result" />
        
            <!--  easy hand eye calibrate  -->
            <include file="$(find easy_handeye)/launch/calibrate.launch">
                <arg name="eye_on_hand" value="false"/>
                <arg name="move_group" value="$(arg move_group)" />
        
                <!-- fill in the following parameters according to your robot's published tf frames -->
                <arg name="robot_base_frame" value="$(arg robot_base_frame)"/>
                <arg name="robot_effector_frame" value="$(arg robot_effector_frame)"/>
        
                <!-- fill in the following parameters according to your tracking system's published tf frames -->
                <arg name="tracking_base_frame" value="$(arg ref_frame)"/>
                <arg name="tracking_marker_frame" value="$(arg marker_frame)"/>
            </include>
        
        </launch>

遇到的问题:
1. import cv2的版本不对(`pip3 install opencv-python` `pip install opencv-contrib-python` 安装位置在~/.local下)
    
        # 查看cv2的路径 发现对的cv2在~/.local下
        import cv2
        help(cv2)  # 是cv2.so文件 可以通过locate定位(根据需要进行updatedb)
        # 查看python path信息
        import sys
        sys.path   
        # '/opt/ros/kinetic/lib/python2.7/dist-packages'在前面, 而对的cv2在~/.local,排在后面
        
        # 在需要用到cv2的地方如下处理即可
        import sys
        sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')
        import cv2
        sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')

2. 无法显示rqt_gui界面的gui操作框
可能是由于conda环境冲突,切换回系统对应的环境就可以了(最开始是把libqt5*卸载之后再安装依赖就可以,之后发现还是得切换回之前的环境)



# 引用
1. [机器人手眼标定Ax=xB（eye to hand和eye in hand）及平面九点法标定](https://blog.csdn.net/yaked/article/details/77161160?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control)
2. [3D 视觉之手眼标定](https://mp.weixin.qq.com/s/nJx1dlpBXaL2_iT_J4W5Kg)
3. [通过ROS控制真实机械臂(15) --- 视觉抓取之手眼标定](https://blog.csdn.net/qq_34935373/article/details/103727968)
